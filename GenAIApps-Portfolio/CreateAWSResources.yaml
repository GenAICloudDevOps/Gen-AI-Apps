# =============================================================================
# AWS CloudFormation Template Documentation
# =============================================================================
# Purpose: Creates a complete infrastructure stack for a web application including:
#   - VPC with public and private subnets
#   - EC2 instance for application hosting
#   - RDS PostgreSQL database
#   - S3 bucket for file storage
#   - IAM user with necessary permissions
#
# Architecture:
# -------------
# 1. Networking:
#    - VPC with CIDR 10.0.0.0/16
#    - Public subnet (10.0.1.0/24) for EC2
#    - Two private subnets (10.0.2.0/24, 10.0.3.0/24) for RDS
#    - NAT Gateway for private subnet internet access
#
# 2. Security:
#    - EC2 Security Group:
#      * SSH (22)
#      * HTTP (80)
#      * HTTPS (443)
#      * Streamlit (8501-8510)
#    - RDS Security Group:
#      * PostgreSQL (5432) from EC2 only
#
# 3. Components:
#    - EC2: t3.medium instance (configurable)
#    - RDS: PostgreSQL 16.3 on db.t4g.micro
#    - S3: Versioned bucket with encryption
#
# Usage:
# ------
# Required Parameters:
#   - EnvironmentName: Prefix for resource names (default: dev)
#   - KeyPairName: EC2 SSH key pair name
#   - EC2InstanceType: Instance size
#   - DBName: Database name
#
# Deployment Methods:
# ------------------
# 1. AWS Console Deployment:
#    a. Navigate to AWS CloudFormation console
#    b. Click "Create stack" > "With new resources (standard)"
#    c. Choose "Upload a template file"
#    d. Upload this YAML file
#    e. Click "Next"
#    f. Enter stack details:
#       - Stack name: <your-stack-name>
#       - EnvironmentName: dev (or your preference)
#       - KeyPairName: Select your existing key pair
#       - EC2InstanceType: Choose instance size (default: t3.medium)
#       - DBName: Enter database name (default: mydb)
#    g. Click "Next" twice (keep default options)
#    h. Review and check acknowledgments
#    i. Click "Create stack"
#    j. Wait for stack creation (~15-20 minutes)
#
# 2. AWS CLI Deployment:
# aws cloudformation create-stack \
#   --stack-name <stack-name> \
#   --template-body file://createec2s3postgres_new.yaml \
#   --parameters \
#     ParameterKey=EnvironmentName,ParameterValue=dev \
#     ParameterKey=KeyPairName,ParameterValue=dev-key-pair
#
# Post-Deployment Steps:
# ---------------------
# 1. Get EC2 Public IP from Outputs tab
# 2. Connect via SSH: ssh -i "your-key.pem" ec2-user@<EC2-Public-IP>
#
# Important Notes:
# ---------------
# 1. Create EC2 key pair before deploying
# 2. Default database credentials should be changed after deployment
# 3. S3 bucket name must be globally unique
# 4. All resources are created in the same region
# =============================================================================

AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudFormation template for creating IAM user, EC2 instance, S3 bucket, and RDS PostgreSQL database'

Parameters:
  EnvironmentName:
    Description: Environment name
    Type: String
    Default: dev

  EC2InstanceType:
    Type: String
    Default: t3.medium
    AllowedValues: 
      - t3.micro
      - t3.small
      - t3.medium
      - t3.large
    Description: EC2 instance type

  DBName:
    Type: String
    Description: Database name
    Default: mydb

  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC to use for resources

  KeyPairName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instance
    Default: dev-key-pair

Resources:
  # VPC and Network Configuration
  MyVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-vpc

  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: !Select [0, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-public-subnet-1

  PrivateSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: us-east-1a
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-private-subnet-1

  # Add second private subnet
  PrivateSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      CidrBlock: 10.0.3.0/24
      AvailabilityZone: us-east-1b
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-private-subnet-2

  InternetGateway:
    Type: AWS::EC2::InternetGateway

  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref MyVPC
      InternetGatewayId: !Ref InternetGateway

  # Route Tables and Routing Configuration
  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref MyVPC
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-public-rt

  PublicRoute:
    Type: AWS::EC2::Route
    DependsOn: AttachGateway
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet1
      RouteTableId: !Ref PublicRouteTable

  NatGatewayEIP:
    Type: AWS::EC2::EIP
    DependsOn: AttachGateway
    Properties:
      Domain: vpc

  NatGateway:
    Type: AWS::EC2::NatGateway
    Properties:
      AllocationId: !GetAtt NatGatewayEIP.AllocationId
      SubnetId: !Ref PublicSubnet1
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-nat

  PrivateRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref MyVPC
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-private-rt

  PrivateRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NatGateway

  PrivateSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PrivateSubnet1
      RouteTableId: !Ref PrivateRouteTable

  PrivateSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PrivateSubnet2
      RouteTableId: !Ref PrivateRouteTable

  # IAM Policies for existing cloud_user
  CloudUserS3Policy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: !Sub '${EnvironmentName}-S3-Access-Policy'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - s3:GetObject
              - s3:PutObject
              - s3:DeleteObject
              - s3:ListBucket
            Resource:
              - !Sub '${MyS3Bucket}/*'
              - !GetAtt MyS3Bucket.Arn
      Users:
        - cloud_user

  CloudUserRDSPolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: !Sub '${EnvironmentName}-RDS-Access-Policy'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - rds:DescribeDBInstances
              - rds:DescribeDBClusters
              - rds:ListTagsForResource
            Resource: !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:db:${PostgreSQLDatabase}'
      Users:
        - cloud_user

  CloudUserEC2Policy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: !Sub '${EnvironmentName}-EC2-Access-Policy'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - ec2:DescribeInstances
              - ec2:DescribeSecurityGroups
              - ec2:DescribeVpcs
              - ec2:DescribeSubnets
            Resource: '*'
      Users:
        - cloud_user

  # S3 Bucket with improved security
  MyS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${EnvironmentName}-${AWS::AccountId}-${AWS::Region}-bucket'
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  # Lambda execution role for S3 folder creation
  S3FolderCreationRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3FolderCreationPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:PutObjectAcl
                Resource: !Sub '${MyS3Bucket}/*'

  # Lambda function to create S3 folders
  S3FolderCreationFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${EnvironmentName}-s3-folder-creator'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt S3FolderCreationRole.Arn
      Timeout: 60
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import json
          
          def lambda_handler(event, context):
              try:
                  s3_client = boto3.client('s3')
                  bucket_name = event['ResourceProperties']['BucketName']
                  folders = event['ResourceProperties']['Folders']
                  
                  if event['RequestType'] == 'Create' or event['RequestType'] == 'Update':
                      # Create folders by putting empty objects with trailing slash
                      for folder in folders:
                          folder_key = folder if folder.endswith('/') else folder + '/'
                          s3_client.put_object(
                              Bucket=bucket_name,
                              Key=folder_key,
                              Body=b'',
                              ContentType='application/x-directory'
                          )
                          print(f"Created folder: {folder_key}")
                      
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {
                          'Message': f'Successfully created {len(folders)} folders in bucket {bucket_name}'
                      })
                  
                  elif event['RequestType'] == 'Delete':
                      # Optionally clean up folders on stack deletion
                      # Note: This will only delete empty folder markers, not actual files
                      for folder in folders:
                          folder_key = folder if folder.endswith('/') else folder + '/'
                          try:
                              s3_client.delete_object(Bucket=bucket_name, Key=folder_key)
                              print(f"Deleted folder marker: {folder_key}")
                          except Exception as e:
                              print(f"Could not delete folder marker {folder_key}: {str(e)}")
                      
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {
                          'Message': 'Folder cleanup completed'
                      })
                  
              except Exception as e:
                  print(f"Error: {str(e)}")
                  cfnresponse.send(event, context, cfnresponse.FAILED, {
                      'Message': f'Error creating S3 folders: {str(e)}'
                  })

  # Custom resource to trigger S3 folder creation
  S3FolderCreation:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: MyS3Bucket
    Properties:
      ServiceToken: !GetAtt S3FolderCreationFunction.Arn
      BucketName: !Ref MyS3Bucket
      Folders:
        - 'App1_RAG-DocuMind'
        - 'App2_PromptEng'
        - 'App3_Nist-AI-RMF'

  # EC2 Security Group with restricted access
  EC2SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId: !Ref MyVPC
      GroupName: !Sub ${EnvironmentName}-ec2-sg
      GroupDescription: Security group for EC2 instance
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 8501
          ToPort: 8510
          CidrIp: 0.0.0.0/0

  # RDS Security Group
  RDSSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId: !Ref MyVPC
      GroupName: !Sub ${EnvironmentName}-rds-sg
      GroupDescription: Security group for RDS PostgreSQL
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 5432
          ToPort: 5432
          SourceSecurityGroupId: !Ref EC2SecurityGroup

  # EC2 Instance
  MyEC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: ami-01816d07b1128cd2d
      InstanceType: !Ref EC2InstanceType
      KeyName: !Ref KeyPairName
      SubnetId: !Ref PublicSubnet1
      SecurityGroupIds: 
        - !Ref EC2SecurityGroup
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-ec2

  # RDS Subnet Group
  RDSSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: Subnet group for RDS
      SubnetIds:
        - !Ref PrivateSubnet1
        - !Ref PrivateSubnet2

  # RDS PostgreSQL Database
  PostgreSQLDatabase:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: !Sub ${EnvironmentName}-postgres
      Engine: postgres
      EngineVersion: '16.3'
      MasterUsername: postgres
      MasterUserPassword: postgres
      DBInstanceClass: db.t4g.micro
      StorageType: gp2
      AllocatedStorage: 30
      VPCSecurityGroups:
        - !Ref RDSSecurityGroup
      DBSubnetGroupName: !Ref RDSSubnetGroup
      PubliclyAccessible: false
      DBName: !Ref DBName
      BackupRetentionPeriod: 0
      MonitoringInterval: 0
      EnablePerformanceInsights: false
      MultiAZ: false
      StorageEncrypted: true

Outputs:
  VPCId:
    Description: VPC ID
    Value: !Ref MyVPC
    Export:
      Name: !Sub '${EnvironmentName}-VPC-ID'

  ExistingIAMUser:
    Description: Existing IAM user with attached policies
    Value: cloud_user
    Export:
      Name: !Sub '${EnvironmentName}-IAM-User'

  EC2InstanceId:
    Description: ID of the EC2 instance
    Value: !Ref MyEC2Instance
    Export:
      Name: !Sub '${EnvironmentName}-EC2-Instance-ID'

  EC2PublicIP:
    Description: Public IP address of the EC2 instance
    Value: !GetAtt MyEC2Instance.PublicIp
    Export:
      Name: !Sub '${EnvironmentName}-EC2-Public-IP'

  S3BucketName:
    Description: Name of the S3 bucket
    Value: !Ref MyS3Bucket
    Export:
      Name: !Sub '${EnvironmentName}-S3-Bucket'

  S3BucketFolders:
    Description: S3 bucket folders created for applications
    Value: !Join 
      - ', '
      - - 'App1_RAG-DocuMind/'
        - 'App2_PromptEng/'
        - 'App3_Nist-AI-RMF/'
    Export:
      Name: !Sub '${EnvironmentName}-S3-Folders'

  DatabaseEndpoint:
    Description: Endpoint of the PostgreSQL database
    Value: !GetAtt PostgreSQLDatabase.Endpoint.Address
    Export:
      Name: !Sub '${EnvironmentName}-DB-Endpoint'

  DatabasePort:
    Description: Port of the PostgreSQL database
    Value: !GetAtt PostgreSQLDatabase.Endpoint.Port
    Export:
      Name: !Sub '${EnvironmentName}-DB-Port'

  DatabaseName:
    Description: Name of the PostgreSQL database
    Value: !Ref DBName
    Export:
      Name: !Sub '${EnvironmentName}-DB-Name'

  DatabaseUsername:
    Description: Username for the PostgreSQL database
    Value: postgres
    Export:
      Name: !Sub '${EnvironmentName}-DB-Username'

  KeyPairName:
    Description: Name of the key pair
    Value: !Ref KeyPairName
    Export:
      Name: !Sub '${EnvironmentName}-KeyPair'

  AWSRegion:
    Description: AWS Region where resources are created
    Value: !Ref 'AWS::Region'
    Export:
      Name: !Sub '${EnvironmentName}-Region'

  # Instructions for cloud_user access keys
  AccessKeyInstructions:
    Description: Instructions to get access keys for cloud_user
    Value: !Sub |
      To get access keys for cloud_user, run these commands:
      
      1. List existing access keys:
         aws iam list-access-keys --user-name cloud_user
      
      2. Create new access key (if needed):
         aws iam create-access-key --user-name cloud_user
      
      3. The policies attached to cloud_user provide access to:
         - S3 bucket: ${MyS3Bucket}
         - RDS instance: ${PostgreSQLDatabase}
         - EC2 describe permissions

  # Environment file template
  EnvironmentVariables:
    Description: Template for .env file configuration
    Value: !Sub |
      # AWS Configuration (Update ACCESS_KEY and SECRET_KEY)
      S3_BUCKET_NAME="${MyS3Bucket}"
      S3_FOLDER_APP1=App1_RAG-DocuMind/
      S3_FOLDER_APP2=App2_PromptEng/
      S3_FOLDER_APP3=App3_Nist-AI-RMF/
      AWS_ACCESS_KEY="<GET_FROM_CLOUD_USER_ACCESS_KEYS>"
      AWS_SECRET_KEY="<GET_FROM_CLOUD_USER_ACCESS_KEYS>"
      AWS_REGION="${AWS::Region}"
      
      # Database Configuration
      POSTGRES_HOST="${PostgreSQLDatabase.Endpoint.Address}"
      POSTGRES_PORT="${PostgreSQLDatabase.Endpoint.Port}"
      POSTGRES_DB="${DBName}"
      POSTGRES_USER="postgres"
      POSTGRES_PASSWORD="postgres"
      
      # External API (Get from Mistral AI)
      MISTRAL_API_KEY="<YOUR_MISTRAL_API_KEY>"
      
      # React Environment Variables
      EC2_PUBLIC_IP="${MyEC2Instance.PublicIp}"
      API_BASE_URL="http://${MyEC2Instance.PublicIp}"