# =============================================================================
# AWS CloudFormation Template Documentation
# =============================================================================
# Purpose: Creates a complete infrastructure stack for a web application including:
#   - VPC with public and private subnets
#   - EC2 instance for application hosting
#   - RDS PostgreSQL database
#   - S3 bucket for file storage
#   - IAM user with necessary permissions
#
# Architecture:
# -------------
# 1. Networking:
#    - VPC with CIDR 10.0.0.0/16
#    - Public subnet (10.0.1.0/24) for EC2
#    - Two private subnets (10.0.2.0/24, 10.0.3.0/24) for RDS
#    - NAT Gateway for private subnet internet access
#
# 2. Security:
#    - EC2 Security Group:
#      * SSH (22)
#      * HTTP (80)
#      * HTTPS (443)
#      * Streamlit (8501-8510)
#    - RDS Security Group:
#      * PostgreSQL (5432) from EC2 only
#
# 3. Components:
#    - EC2: t3.medium instance (configurable)
#    - RDS: PostgreSQL 16.3 on db.t4g.micro
#    - S3: Versioned bucket with encryption
#
# Usage:
# ------
# Required Parameters:
#   - EnvironmentName: Prefix for resource names (default: dev)
#   - KeyPairName: EC2 SSH key pair name
#   - EC2InstanceType: Instance size
#   - DBName: Database name
#
# Deployment Methods:
# ------------------
# 1. AWS Console Deployment:
#    a. Navigate to AWS CloudFormation console
#    b. Click "Create stack" > "With new resources (standard)"
#    c. Choose "Upload a template file"
#    d. Upload this YAML file
#    e. Click "Next"
#    f. Enter stack details:
#       - Stack name: <your-stack-name>
#       - EnvironmentName: dev (or your preference)
#       - KeyPairName: Select your existing key pair
#       - EC2InstanceType: Choose instance size (default: t3.medium)
#       - DBName: Enter database name (default: mydb)
#    g. Click "Next" twice (keep default options)
#    h. Review and check acknowledgments
#    i. Click "Create stack"
#    j. Wait for stack creation (~15-20 minutes)
#
# 2. AWS CLI Deployment:
# aws cloudformation create-stack \
#   --stack-name <stack-name> \
#   --template-body file://createec2s3postgres_new.yaml \
#   --parameters \
#     ParameterKey=EnvironmentName,ParameterValue=dev \
#     ParameterKey=KeyPairName,ParameterValue=dev-key-pair
#
# Post-Deployment Steps:
# ---------------------
# 1. Get EC2 Public IP from Outputs tab
# 2. Connect via SSH: ssh -i "your-key.pem" ec2-user@<EC2-Public-IP>
#
# Important Notes:
# ---------------
# 1. Create EC2 key pair before deploying
# 2. Default database credentials should be changed after deployment
# 3. S3 bucket name must be globally unique
# 4. All resources are created in the same region
# =============================================================================

AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudFormation template for creating IAM user, EC2 instance, S3 bucket, and RDS PostgreSQL database'

Parameters:
  EnvironmentName:
    Description: Environment name
    Type: String
    Default: dev

  EC2InstanceType:
    Type: String
    Default: t3.medium
    AllowedValues: 
      - t3.micro
      - t3.small
      - t3.medium
      - t3.large
    Description: EC2 instance type

  DBName:
    Type: String
    Description: Database name
    Default: mydb

  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC to use for resources

  KeyPairName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instance
    Default: dev-key-pair

Resources:
  # VPC and Network Configuration
  MyVPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-vpc

  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: !Select [0, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-public-subnet-1

  PrivateSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: us-east-1a
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-private-subnet-1

  # Add second private subnet
  PrivateSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref MyVPC
      CidrBlock: 10.0.3.0/24
      AvailabilityZone: us-east-1b
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-private-subnet-2

  InternetGateway:
    Type: AWS::EC2::InternetGateway

  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref MyVPC
      InternetGatewayId: !Ref InternetGateway

  # Route Tables and Routing Configuration
  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref MyVPC
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-public-rt

  PublicRoute:
    Type: AWS::EC2::Route
    DependsOn: AttachGateway
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  PublicSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet1
      RouteTableId: !Ref PublicRouteTable

  NatGatewayEIP:
    Type: AWS::EC2::EIP
    DependsOn: AttachGateway
    Properties:
      Domain: vpc

  NatGateway:
    Type: AWS::EC2::NatGateway
    Properties:
      AllocationId: !GetAtt NatGatewayEIP.AllocationId
      SubnetId: !Ref PublicSubnet1
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-nat

  PrivateRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref MyVPC
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-private-rt

  PrivateRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NatGateway

  PrivateSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PrivateSubnet1
      RouteTableId: !Ref PrivateRouteTable

  PrivateSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PrivateSubnet2
      RouteTableId: !Ref PrivateRouteTable

  # Create IAM User ec2-user
  EC2AdminUser:
    Type: AWS::IAM::User
    Properties:
      UserName: ec2-user
      Path: /
      Tags:
        - Key: Environment
          Value: !Ref EnvironmentName
        - Key: Purpose
          Value: GenAI-Apps-Portfolio

  # S3 Access Policy for ec2-user
  EC2UserS3Policy:
    Type: AWS::IAM::Policy
    DependsOn: MyS3Bucket
    Properties:
      PolicyName: !Sub '${EnvironmentName}-EC2User-S3-Access-Policy'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - s3:GetObject
              - s3:PutObject
              - s3:DeleteObject
              - s3:ListBucket
              - s3:GetBucketLocation
              - s3:ListBucketMultipartUploads
              - s3:ListMultipartUploadParts
              - s3:AbortMultipartUpload
            Resource:
              - !Sub 'arn:aws:s3:::${MyS3Bucket}/*'
              - !Sub 'arn:aws:s3:::${MyS3Bucket}'
          - Effect: Allow
            Action:
              - s3:ListAllMyBuckets
            Resource: '*'
      Users:
        - !Ref EC2AdminUser

  # RDS Access Policy for ec2-user
  EC2UserRDSPolicy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: !Sub '${EnvironmentName}-EC2User-RDS-Access-Policy'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - rds:DescribeDBInstances
              - rds:DescribeDBClusters
              - rds:DescribeDBSubnetGroups
              - rds:DescribeDBParameterGroups
              - rds:DescribeDBClusterParameterGroups
              - rds:ListTagsForResource
            Resource: 
              - !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:db:*'
              - !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:cluster:*'
              - !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:subgrp:*'
              - !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:pg:*'
              - !Sub 'arn:aws:rds:${AWS::Region}:${AWS::AccountId}:cluster-pg:*'
      Users:
        - !Ref EC2AdminUser

  # EC2 Access Policy for ec2-user
  EC2UserEC2Policy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: !Sub '${EnvironmentName}-EC2User-EC2-Access-Policy'
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Action:
              - ec2:DescribeInstances
              - ec2:DescribeInstanceStatus
              - ec2:DescribeSecurityGroups
              - ec2:DescribeVpcs
              - ec2:DescribeSubnets
              - ec2:DescribeKeyPairs
              - ec2:DescribeImages
              - ec2:DescribeAvailabilityZones
              - ec2:DescribeRegions
            Resource: '*'
      Users:
        - !Ref EC2AdminUser

  # S3 Bucket with improved security
  MyS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${EnvironmentName}-${AWS::AccountId}-${AWS::Region}-bucket'
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  # Lambda execution role for S3 folder creation
  S3FolderCreationRole:
    Type: AWS::IAM::Role
    DependsOn: MyS3Bucket
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3FolderCreationPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:PutObjectAcl
                Resource: !Sub 'arn:aws:s3:::${MyS3Bucket}/*'

  # Lambda function to create S3 folders
  S3FolderCreationFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${EnvironmentName}-s3-folder-creator'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt S3FolderCreationRole.Arn
      Timeout: 60
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import json
          
          def lambda_handler(event, context):
              try:
                  s3_client = boto3.client('s3')
                  bucket_name = event['ResourceProperties']['BucketName']
                  folders = event['ResourceProperties']['Folders']
                  
                  if event['RequestType'] == 'Create' or event['RequestType'] == 'Update':
                      # Create folders by putting empty objects with trailing slash
                      for folder in folders:
                          folder_key = folder if folder.endswith('/') else folder + '/'
                          s3_client.put_object(
                              Bucket=bucket_name,
                              Key=folder_key,
                              Body=b'',
                              ContentType='application/x-directory'
                          )
                          print(f"Created folder: {folder_key}")
                      
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {
                          'Message': f'Successfully created {len(folders)} folders in bucket {bucket_name}'
                      })
                  
                  elif event['RequestType'] == 'Delete':
                      # Optionally clean up folders on stack deletion
                      # Note: This will only delete empty folder markers, not actual files
                      for folder in folders:
                          folder_key = folder if folder.endswith('/') else folder + '/'
                          try:
                              s3_client.delete_object(Bucket=bucket_name, Key=folder_key)
                              print(f"Deleted folder marker: {folder_key}")
                          except Exception as e:
                              print(f"Could not delete folder marker {folder_key}: {str(e)}")
                      
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {
                          'Message': 'Folder cleanup completed'
                      })
                  
              except Exception as e:
                  print(f"Error: {str(e)}")
                  cfnresponse.send(event, context, cfnresponse.FAILED, {
                      'Message': f'Error creating S3 folders: {str(e)}'
                  })

  # Custom resource to trigger S3 folder creation
  S3FolderCreation:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: MyS3Bucket
    Properties:
      ServiceToken: !GetAtt S3FolderCreationFunction.Arn
      BucketName: !Ref MyS3Bucket
      Folders:
        - 'App1_RAG-DocuMind'
        - 'App2_PromptEng'
        - 'App3_Nist-AI-RMF'

  # EC2 Security Group with restricted access
  EC2SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId: !Ref MyVPC
      GroupName: !Sub ${EnvironmentName}-ec2-sg
      GroupDescription: Security group for EC2 instance
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 8501
          ToPort: 8510
          CidrIp: 0.0.0.0/0

  # RDS Security Group
  RDSSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      VpcId: !Ref MyVPC
      GroupName: !Sub ${EnvironmentName}-rds-sg
      GroupDescription: Security group for RDS PostgreSQL
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 5432
          ToPort: 5432
          SourceSecurityGroupId: !Ref EC2SecurityGroup

  # EC2 Instance
  MyEC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: ami-01816d07b1128cd2d
      InstanceType: !Ref EC2InstanceType
      KeyName: !Ref KeyPairName
      SubnetId: !Ref PublicSubnet1
      SecurityGroupIds: 
        - !Ref EC2SecurityGroup
      Tags:
        - Key: Name
          Value: !Sub ${EnvironmentName}-ec2

  # RDS Subnet Group
  RDSSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: Subnet group for RDS
      SubnetIds:
        - !Ref PrivateSubnet1
        - !Ref PrivateSubnet2

  # RDS PostgreSQL Database
  PostgreSQLDatabase:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: !Sub ${EnvironmentName}-postgres
      Engine: postgres
      EngineVersion: '16.3'
      MasterUsername: postgres
      MasterUserPassword: postgres
      DBInstanceClass: db.t4g.micro
      StorageType: gp2
      AllocatedStorage: 30
      VPCSecurityGroups:
        - !Ref RDSSecurityGroup
      DBSubnetGroupName: !Ref RDSSubnetGroup
      PubliclyAccessible: false
      DBName: !Ref DBName
      BackupRetentionPeriod: 0
      MonitoringInterval: 0
      EnablePerformanceInsights: false
      MultiAZ: false
      StorageEncrypted: true

Outputs:
  VPCId:
    Description: VPC ID
    Value: !Ref MyVPC
    Export:
      Name: !Sub '${EnvironmentName}-VPC-ID'

  IAMUserName:
    Description: Name of the IAM user created
    Value: !Ref EC2AdminUser
    Export:
      Name: !Sub '${EnvironmentName}-IAM-User'

  EC2InstanceId:
    Description: ID of the EC2 instance
    Value: !Ref MyEC2Instance
    Export:
      Name: !Sub '${EnvironmentName}-EC2-Instance-ID'

  EC2PublicIP:
    Description: Public IP address of the EC2 instance
    Value: !GetAtt MyEC2Instance.PublicIp
    Export:
      Name: !Sub '${EnvironmentName}-EC2-Public-IP'

  S3BucketName:
    Description: Name of the S3 bucket
    Value: !Ref MyS3Bucket
    Export:
      Name: !Sub '${EnvironmentName}-S3-Bucket'

  S3BucketFolders:
    Description: S3 bucket folders created for applications
    Value: !Join 
      - ', '
      - - 'App1_RAG-DocuMind/'
        - 'App2_PromptEng/'
        - 'App3_Nist-AI-RMF/'
    Export:
      Name: !Sub '${EnvironmentName}-S3-Folders'

  DatabaseEndpoint:
    Description: Endpoint of the PostgreSQL database
    Value: !GetAtt PostgreSQLDatabase.Endpoint.Address
    Export:
      Name: !Sub '${EnvironmentName}-DB-Endpoint'

  DatabasePort:
    Description: Port of the PostgreSQL database
    Value: !GetAtt PostgreSQLDatabase.Endpoint.Port
    Export:
      Name: !Sub '${EnvironmentName}-DB-Port'

  DatabaseName:
    Description: Name of the PostgreSQL database
    Value: !Ref DBName
    Export:
      Name: !Sub '${EnvironmentName}-DB-Name'

  DatabaseUsername:
    Description: Username for the PostgreSQL database
    Value: postgres
    Export:
      Name: !Sub '${EnvironmentName}-DB-Username'

  KeyPairName:
    Description: Name of the key pair
    Value: !Ref KeyPairName
    Export:
      Name: !Sub '${EnvironmentName}-KeyPair'

  AWSRegion:
    Description: AWS Region where resources are created
    Value: !Ref 'AWS::Region'
    Export:
      Name: !Sub '${EnvironmentName}-Region'

  # Security Notice
  SecurityNotice:
    Description: Important security information
    Value: !Sub |
      SECURITY NOTICE:
      - Create AWS Access Keys manually for the IAM user: ${EC2AdminUser}
      - Go to AWS Console > IAM > Users > ${EC2AdminUser} > Security credentials
      - Click "Create access key" and store credentials securely
      - Never commit these credentials to version control
      - Use the manually created keys in your .env file

  # Complete Environment file template with actual values
  EnvironmentVariables:
    Description: Complete .env file configuration with actual values
    Value: !Sub |
      # AWS Configuration - ADD YOUR MANUAL ACCESS KEYS
      S3_BUCKET_NAME="${MyS3Bucket}"
      S3_FOLDER_APP1=App1_RAG-DocuMind/
      S3_FOLDER_APP2=App2_PromptEng/
      S3_FOLDER_APP3=App3_Nist-AI-RMF/
      AWS_ACCESS_KEY="<YOUR_MANUAL_ACCESS_KEY>"
      AWS_SECRET_KEY="<YOUR_MANUAL_SECRET_KEY>"
      AWS_REGION="${AWS::Region}"
      
      # Database Configuration - READY TO USE
      POSTGRES_HOST="${PostgreSQLDatabase.Endpoint.Address}"
      POSTGRES_PORT="${PostgreSQLDatabase.Endpoint.Port}"
      POSTGRES_DB="${DBName}"
      POSTGRES_USER="postgres"
      POSTGRES_PASSWORD="postgres"
      
      # External API (Get from Mistral AI)
      MISTRAL_API_KEY="<YOUR_MISTRAL_API_KEY>"
      
      # React Environment Variables - READY TO USE
      EC2_PUBLIC_IP="${MyEC2Instance.PublicIp}"
      API_BASE_URL="http://${MyEC2Instance.PublicIp}"

  # Deployment Instructions
  DeploymentInstructions:
    Description: Step-by-step deployment instructions
    Value: !Sub |
      DEPLOYMENT INSTRUCTIONS:
      
      1. CREATE AWS ACCESS KEYS MANUALLY:
         - Go to AWS Console > IAM > Users > ${EC2AdminUser}
         - Click "Security credentials" tab
         - Click "Create access key" > Choose "Application running outside AWS"
         - Copy the Access Key ID and Secret Access Key
      
      2. COPY ENVIRONMENT VARIABLES:
         Copy the 'EnvironmentVariables' output to your .env file
      
      3. ADD API KEYS:
         - Replace <YOUR_MANUAL_ACCESS_KEY> with your AWS Access Key ID
         - Replace <YOUR_MANUAL_SECRET_KEY> with your AWS Secret Access Key
         - Get Mistral API key from https://console.mistral.ai/
         - Replace <YOUR_MISTRAL_API_KEY> in the .env file
      
      4. CONNECT TO EC2:
         ssh -i "your-key.pem" ec2-user@${MyEC2Instance.PublicIp}
      
      5. DEPLOY APPLICATIONS:
         Upload your code and run: docker-compose up -d
      
      6. ACCESS APPLICATIONS:
         React Frontend: http://${MyEC2Instance.PublicIp}:3000
         RAG-DocuMind: http://${MyEC2Instance.PublicIp}:8501
         Prompt Engineering: http://${MyEC2Instance.PublicIp}:8502
         NIST AI RMF: http://${MyEC2Instance.PublicIp}:8503
         Multi-Agent CrewAI: http://${MyEC2Instance.PublicIp}:8504
         Conversational AI: http://${MyEC2Instance.PublicIp}:8000
         Interpretable AI: http://${MyEC2Instance.PublicIp}:8506